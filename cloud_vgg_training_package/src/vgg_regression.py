import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from fast_dataset import FastImageDataset  # ä¿®å¤å¯¼å…¥ï¼Œä½¿ç”¨FastImageDatasetæ›¿ä»£LocalImageDataset
from torchvision import transforms
from torchvision import models
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
import os
import cv2
from cbam import CBAM
import argparse
import time
import random
from PIL import Image


# å¯¼å…¥å­—ä½“è®¾ç½®å·¥å…·
from font_utils import CHINESE_SUPPORTED, get_labels, suppress_font_warnings
# å¯¼å…¥è®­ç»ƒç›‘æ§æ¨¡å—
from training_monitor import TrainingMonitor
# å¯¼å…¥ç»Ÿä¸€çš„æ•°æ®é›†é…ç½®
from dataset_config import DatasetConfig

# æŠ‘åˆ¶å­—ä½“è­¦å‘Š
suppress_font_warnings()

# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # åœ¨è®­ç»ƒå¼€å§‹åå¯ç”¨benchmarkä»¥æå‡æ€§èƒ½
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False  # åˆå§‹åŒ–æ—¶ç¦ç”¨ï¼Œè®­ç»ƒæ—¶å¯ç”¨

def enable_cudnn_benchmark():
    """è®­ç»ƒå¼€å§‹åå¯ç”¨cudnn benchmarkä»¥æå‡è®­ç»ƒæ€§èƒ½"""
    torch.backends.cudnn.benchmark = True
    print("å·²å¯ç”¨CUDNN benchmarkä»¥æå‡è®­ç»ƒæ€§èƒ½", flush=True)

set_seed(42)

# ç§»é™¤æ¨¡å—çº§åˆ«çš„å¯åŠ¨ä¿¡æ¯ï¼Œé¿å…åœ¨å¯¼å…¥æ—¶è¾“å‡º

class VGGRegressionCBAM(nn.Module):
    def __init__(self, freeze_features=True, debug_mode=False):
        super(VGGRegressionCBAM, self).__init__()
        vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
        
        # éªŒè¯VGG16ç»“æ„ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if debug_mode:
            print("VGG16ç‰¹å¾å±‚ç»“æ„:", flush=True)
            for i, layer in enumerate(vgg.features):
                print(f"  Layer {i}: {layer}", flush=True)
        else:
            print(f"åŠ è½½VGG16é¢„è®­ç»ƒæ¨¡å‹ï¼Œå…±{len(vgg.features)}å±‚", flush=True)
        
        self.features = nn.Sequential()
        # VGG16çš„æ­£ç¡®blockåˆ†å‰²ï¼š
        # Block1: 0-4 (Conv-ReLU-Conv-ReLU-MaxPool) -> 64 channels
        # Block2: 5-9 (Conv-ReLU-Conv-ReLU-MaxPool) -> 128 channels  
        # Block3: 10-16 (Conv-ReLU-Conv-ReLU-Conv-ReLU-MaxPool) -> 256 channels
        # Block4: 17-23 (Conv-ReLU-Conv-ReLU-Conv-ReLU-MaxPool) -> 512 channels
        # Block5: 24-30 (Conv-ReLU-Conv-ReLU-Conv-ReLU-MaxPool) -> 512 channels
        block_indices = [4, 9, 16, 23, 30]  # æ¯ä¸ªblockçš„æœ€åä¸€å±‚ç´¢å¼•
        in_channels = [64, 128, 256, 512, 512]
        last_idx = 0
        
        # åˆ†åˆ«å¤„ç†VGGå±‚å’ŒCBAMå±‚çš„å†»ç»“
        vgg_layers = []
        cbam_layers = []
        
        for i, idx in enumerate(block_indices):
            print(f"å¤„ç†Block {i+1}: layers {last_idx}-{idx}, è¾“å‡ºé€šé“æ•°: {in_channels[i]}", flush=True)
            
            # æ·»åŠ VGGå±‚
            for j in range(last_idx, idx+1):
                layer_name = f'vgg_{j}'
                vgg_layer = vgg.features[j]
                self.features.add_module(layer_name, vgg_layer)
                vgg_layers.append(vgg_layer)
            
            # æ·»åŠ CBAMå±‚
            cbam_layer = CBAM(in_channels[i])
            cbam_name = f'cbam_{i+1}'
            self.features.add_module(cbam_name, cbam_layer)
            cbam_layers.append(cbam_layer)
            print(f"  æ·»åŠ CBAMå±‚: {cbam_name}, é€šé“æ•°: {in_channels[i]}", flush=True)
            
            last_idx = idx+1
        
        # åªå†»ç»“VGGçš„é¢„è®­ç»ƒå±‚ï¼Œä¿æŒCBAMå±‚å¯è®­ç»ƒ
        if freeze_features:
            for layer in vgg_layers:
                for param in layer.parameters():
                    param.requires_grad = False
            print("VGGé¢„è®­ç»ƒå±‚å·²å†»ç»“ï¼ŒCBAMæ³¨æ„åŠ›å±‚ä¿æŒå¯è®­ç»ƒçŠ¶æ€", flush=True)
        
        self.reg_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((7, 7)),
            nn.Flatten(),
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(4096, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1024, 1)
        )
        
        # æƒé‡åˆå§‹åŒ–
        self._initialize_weights()
        
        # éªŒè¯æ¨¡å‹ç»“æ„
        self._verify_model_structure()
        
        # æ‰“å°å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        print(f"æ¨¡å‹å‚æ•°ç»Ÿè®¡:", flush=True)
        print(f"  æ€»å‚æ•°: {total_params:,}", flush=True)
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)", flush=True)
        print(f"  å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)", flush=True)
        
        # è®¡ç®—æ¨¡å‹å¤§å°
        model_size_mb = total_params * 4 / (1024 * 1024)  # å‡è®¾float32
        print(f"  æ¨¡å‹å¤§å°: {model_size_mb:.1f} MB", flush=True)
        
    def _initialize_weights(self):
        """åˆå§‹åŒ–CBAMå±‚å’Œå›å½’å¤´çš„æƒé‡"""
        for name, m in self.named_modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Conv2d):
                # åªåˆå§‹åŒ–CBAMä¸­çš„å·ç§¯å±‚ï¼Œä¸å½±å“é¢„è®­ç»ƒçš„VGGå±‚
                if 'cbam' in name.lower():
                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                # åªåˆå§‹åŒ–CBAMä¸­çš„BatchNormå±‚
                if 'cbam' in name.lower():
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
        print("æƒé‡åˆå§‹åŒ–å®Œæˆ: Xavieråˆå§‹åŒ–çº¿æ€§å±‚ï¼ŒKaimingåˆå§‹åŒ–CBAMå·ç§¯å±‚", flush=True)
        
    def _verify_model_structure(self):
        """éªŒè¯æ¨¡å‹ç»“æ„æ˜¯å¦æ­£ç¡®"""
        cbam_count = 0
        vgg_count = 0
        for name, module in self.features.named_modules():
            if 'cbam' in name and hasattr(module, 'channel_attention'):
                cbam_count += 1
            elif 'vgg' in name and isinstance(module, (nn.Conv2d, nn.ReLU, nn.MaxPool2d)):
                vgg_count += 1
        
        print(f"æ¨¡å‹ç»“æ„éªŒè¯:", flush=True)
        print(f"  æ£€æµ‹åˆ°CBAMå±‚æ•°é‡: {cbam_count}", flush=True)
        print(f"  æ£€æµ‹åˆ°VGGå±‚æ•°é‡: {vgg_count}", flush=True)
        
        if cbam_count != 5:
            print(f"è­¦å‘Š: æœŸæœ›5ä¸ªCBAMå±‚ï¼Œå®é™…æ£€æµ‹åˆ°{cbam_count}ä¸ª", flush=True)
        else:
            print("âœ“ CBAMå±‚æ•°é‡æ­£ç¡®", flush=True)
        
    def forward(self, x):
        x = self.features(x)
        x = self.reg_head(x)
        return x

def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=30, start_epoch=0, use_amp=True, scheduler=None, model_save_path='best_vgg_model.pth'):
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 10  # æ—©åœè€å¿ƒå€¼
    
    # é‡æ–°å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.amp.GradScaler('cuda') if use_amp else None
    
    print(f"è®­ç»ƒé…ç½®: æ—©åœè€å¿ƒå€¼={early_stop_patience}, æ¢¯åº¦è£å‰ª=1.0, æ··åˆç²¾åº¦={use_amp}, æƒé‡è¡°å‡=1e-4", flush=True)
    
    # åˆå§‹åŒ–è®­ç»ƒç›‘æ§å™¨
    monitor_dir = 'monitoring_results_vgg'
    if 'bg0' in model_save_path:
        monitor_dir = 'monitoring_results_vgg_bg0'
    elif 'bg1' in model_save_path:
        monitor_dir = 'monitoring_results_vgg_bg1'
    
    training_monitor = TrainingMonitor(model_type='vgg', save_dir=monitor_dir, device=device)
    print(f"è®­ç»ƒç›‘æ§å™¨å·²åˆå§‹åŒ–ï¼Œç»“æœä¿å­˜è‡³: {monitor_dir}", flush=True)
    
    # è·å–ä¸€ä¸ªæ ·æœ¬å›¾åƒç”¨äºç›‘æ§
    sample_image = None
    sample_concentration = None
    try:
        for inputs, targets in val_loader:
            sample_image = inputs[0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
            sample_concentration = targets[0].item()
            break
        print(f"è·å–ç›‘æ§æ ·æœ¬å›¾åƒæˆåŠŸï¼Œæµ“åº¦: {sample_concentration}", flush=True)
    except Exception as e:
        print(f"è·å–ç›‘æ§æ ·æœ¬å›¾åƒå¤±è´¥: {e}", flush=True)
    
    for epoch in range(start_epoch, num_epochs):
        model.train()
        running_loss = 0.0
        print(f"\nå¼€å§‹Epoch {epoch + 1}/{num_epochs} - {time.strftime('%H:%M:%S')}", flush=True)
        print("æ­£åœ¨åŠ è½½ç¬¬ä¸€ä¸ªbatch...", flush=True)
        
        batch_10_start_time = time.time()  # æ¯10ä¸ªbatchçš„è®¡æ—¶
        
        for i, (inputs, targets) in enumerate(train_loader):
            batch_start_time = time.time()
            
            if i == 0:
                print(f"æˆåŠŸåŠ è½½ç¬¬ä¸€ä¸ªbatchï¼Œshape: {inputs.shape} - {time.strftime('%H:%M:%S')}", flush=True)
                print(f"å®é™…batch_size: {inputs.shape[0]}", flush=True)
                print(f"è¾“å…¥æ•°æ®ç±»å‹: {inputs.dtype}, è®¾å¤‡: {inputs.device}", flush=True)
                
                # æ˜¾ç¤ºGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                if torch.cuda.is_available():
                    print(f"è®­ç»ƒå¼€å§‹æ—¶GPUå†…å­˜: å·²ç”¨={torch.cuda.memory_allocated() / 1024**3:.2f}GB, ç¼“å­˜={torch.cuda.memory_reserved() / 1024**3:.2f}GB", flush=True)
            
            # é‡æ–°æµ‹é‡æ•°æ®åŠ è½½æ—¶é—´ï¼ˆä»ä¸Šä¸€ä¸ªbatchç»“æŸåˆ°å½“å‰batchå¼€å§‹ï¼‰
            if i > 0:
                data_load_time = batch_start_time - last_batch_end_time
            else:
                data_load_time = 0.0  # ç¬¬ä¸€ä¸ªbatchçš„åŠ è½½æ—¶é—´å·²ç»åŒ…å«åœ¨å¯åŠ¨æ—¶é—´ä¸­
                
            # åªåœ¨å‰3ä¸ªbatchæ˜¾ç¤ºæ•°æ®åŠ è½½è€—æ—¶
            if i < 3:
                print(f"Batch {i+1}: æ•°æ®åŠ è½½è€—æ—¶ {data_load_time:.2f}ç§’, batch_size={inputs.shape[0]}", flush=True)
            
            compute_start_time = time.time()
            inputs = inputs.to(device)
            targets = targets.to(device).float().view(-1, 1)
            
            gpu_transfer_time = time.time() - compute_start_time
            if i == 0:
                print(f"æ•°æ®å·²ç§»è‡³GPUï¼Œä¼ è¾“è€—æ—¶ {gpu_transfer_time:.2f}ç§’ - {time.strftime('%H:%M:%S')}", flush=True)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            forward_start_time = time.time()
            if use_amp:
                with torch.amp.autocast('cuda'):
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
            else:
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            torch.cuda.synchronize()  # ç­‰å¾…GPUè®¡ç®—å®Œæˆ
            forward_time = time.time() - forward_start_time
            
            backward_start_time = time.time()
            if use_amp and scaler:
                scaler.scale(loss).backward()
                # æ¢¯åº¦è£å‰ª
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            torch.cuda.synchronize()  # ç­‰å¾…GPUè®¡ç®—å®Œæˆ
            backward_time = time.time() - backward_start_time
            
            total_batch_time = time.time() - batch_start_time
            last_batch_end_time = time.time()  # è®°å½•å½“å‰batchç»“æŸæ—¶é—´
            
            # åªåœ¨å‰3ä¸ªbatchæ˜¾ç¤ºè¯¦ç»†è€—æ—¶
            if i < 3:
                print(f"Batch {i+1} è¯¦ç»†è€—æ—¶: æ•°æ®åŠ è½½={data_load_time:.2f}s, å‰å‘ä¼ æ’­={forward_time:.2f}s, åå‘ä¼ æ’­={backward_time:.2f}s, æ€»è®¡={total_batch_time:.2f}s", flush=True)
            
            running_loss += loss.item()
            
            # æ¯10ä¸ªbatchçš„æ€§èƒ½ç›‘æµ‹
            if (i + 1) % 10 == 0:
                batch_10_time = time.time() - batch_10_start_time
                avg_batch_time = batch_10_time / 10
                
                # GPUå†…å­˜ç›‘æ§
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    gpu_cached = torch.cuda.memory_reserved() / 1024**3
                    print(f'[Epoch {epoch + 1}, Batch {i + 1}] è®­ç»ƒæŸå¤±: {running_loss / 10:.3f}, æœ€è¿‘10batchè€—æ—¶: {batch_10_time:.2f}s, å¹³å‡æ¯batch: {avg_batch_time:.2f}s, GPUå†…å­˜: {gpu_memory:.1f}GB/{gpu_cached:.1f}GB', flush=True)
                else:
                    print(f'[Epoch {epoch + 1}, Batch {i + 1}] è®­ç»ƒæŸå¤±: {running_loss / 10:.3f}, æœ€è¿‘10batchè€—æ—¶: {batch_10_time:.2f}s, å¹³å‡æ¯batch: {avg_batch_time:.2f}s', flush=True)
                
                running_loss = 0.0
                batch_10_start_time = time.time()  # é‡ç½®10batchè®¡æ—¶å™¨
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_predictions = []
        val_targets = []
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs = inputs.to(device)
                targets = targets.to(device).float().view(-1, 1)
                if use_amp:
                    with torch.amp.autocast('cuda'):
                        predictions = model(inputs)
                        loss = criterion(predictions, targets)
                else:
                    predictions = model(inputs)
                    loss = criterion(predictions, targets)
                val_loss += loss.item()
                val_predictions.extend(predictions.cpu().numpy())
                val_targets.extend(targets.cpu().numpy())
        val_loss /= len(val_loader)
        r2 = r2_score(val_targets, val_predictions)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨æ›´æ–°
        if scheduler:
            scheduler.step(val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            print(f'Epoch {epoch + 1} éªŒè¯æŸå¤±: {val_loss:.3f}, RÂ² åˆ†æ•°: {r2:.3f}, å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}')
        else:
            print(f'Epoch {epoch + 1} éªŒè¯æŸå¤±: {val_loss:.3f}, RÂ² åˆ†æ•°: {r2:.3f}')
        
        # æ—©åœæœºåˆ¶
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), model_save_path)
            print(f'ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° {model_save_path}ï¼ŒéªŒè¯æŸå¤±: {val_loss:.3f}')
        else:
            patience_counter += 1
            print(f'éªŒè¯æŸå¤±æœªæ”¹å–„ï¼Œè€å¿ƒè®¡æ•°å™¨: {patience_counter}/{early_stop_patience}')
            
            if patience_counter >= early_stop_patience:
                print(f'æ—©åœè§¦å‘ï¼è¿ç»­{early_stop_patience}ä¸ªepochéªŒè¯æŸå¤±æœªæ”¹å–„ï¼Œåœæ­¢è®­ç»ƒã€‚')
                break
        
        # æ¯5ä¸ªepochç”Ÿæˆé¢„æµ‹å›¾å’ŒGrad-CAMç›‘æ§
        if epoch % 5 == 0:
            try:
                # è·å–æ ‡ç­¾
                labels = get_labels(CHINESE_SUPPORTED)
                
                # ç”Ÿæˆé¢„æµ‹å¯¹æ¯”å›¾
                plt.figure(figsize=(10, 6))
                plt.scatter(val_targets, val_predictions, alpha=0.5)
                plt.plot([min(val_targets), max(val_targets)], [min(val_targets), max(val_targets)], 'r--')
                plt.xlabel(labels['true_concentration'])
                plt.ylabel(labels['predicted_concentration'])
                plt.title(f"{labels['epoch']} {epoch + 1} {labels['prediction_vs_true']} (RÂ² = {r2:.3f})")
                prediction_plot_path = f'vgg_prediction_plot_epoch_{epoch + 1}.png'
                plt.savefig(prediction_plot_path)
                plt.close()
                print(f'âœ“ é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜: {prediction_plot_path}', flush=True)
                
                # ç”ŸæˆGrad-CAMç›‘æ§ï¼ˆå¦‚æœæœ‰æ ·æœ¬å›¾åƒï¼‰
                if sample_image is not None:
                    print(f"æ­£åœ¨ç”ŸæˆEpoch {epoch + 1}çš„Grad-CAMç›‘æ§...", flush=True)
                    analysis_result = training_monitor.visualize_gradcam_with_regions(
                        model, sample_image, epoch + 1, 
                        save_name=f'vgg_gradcam_epoch_{epoch + 1}'
                    )
                    
                    if analysis_result:
                        # è®°å½•ç›‘æ§ç»“æœ
                        regions_attention = analysis_result['regions_attention']
                        attention_ratios = analysis_result['attention_ratios']
                        
                        print(f"=== Epoch {epoch + 1} æ³¨æ„åŠ›åˆ†æ ===", flush=True)
                        print(f"ä¸­å¿ƒåŒºåŸŸæ³¨æ„åŠ›: {regions_attention['center']:.3f}", flush=True)
                        print(f"æ°´å°åŒºåŸŸæ³¨æ„åŠ›(ä¸­): {regions_attention['watermark_medium']:.3f}", flush=True)
                        print(f"æ°´å°/ä¸­å¿ƒæ³¨æ„åŠ›æ¯”ä¾‹: {attention_ratios['medium_ratio']:.3f}", flush=True)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Š
                        has_warning, warning_msg = training_monitor.check_watermark_attention(analysis_result)
                        if has_warning:
                            print(f"âš ï¸ æ³¨æ„åŠ›è­¦å‘Š: {warning_msg}", flush=True)
                        else:
                            print("âœ“ æ³¨æ„åŠ›åˆ†å¸ƒæ­£å¸¸", flush=True)
                
            except Exception as e:
                print(f"ç”Ÿæˆç›‘æ§å¯è§†åŒ–æ—¶å‡ºé”™: {e}", flush=True)
    
    print(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.3f}", flush=True)
    
    # ç”Ÿæˆæœ€ç»ˆç›‘æ§æŠ¥å‘Š
    try:
        report_name = 'vgg_training_monitoring_report'
        if 'bg0' in model_save_path:
            report_name = 'vgg_training_monitoring_report_bg0'
        elif 'bg1' in model_save_path:
            report_name = 'vgg_training_monitoring_report_bg1'
        
        report_path = training_monitor.generate_monitoring_report(save_name=report_name)
        if report_path:
            print(f"âœ“ è®­ç»ƒç›‘æ§æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}", flush=True)
    except Exception as e:
        print(f"ç”Ÿæˆç›‘æ§æŠ¥å‘Šæ—¶å‡ºé”™: {e}", flush=True)

    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("å·²æ¸…ç†GPUç¼“å­˜", flush=True)

def main():
    print("=== è¿›å…¥mainå‡½æ•° ===", flush=True)
    print("æ­£åœ¨è§£æå‘½ä»¤è¡Œå‚æ•°...", flush=True)
    parser = argparse.ArgumentParser(description='VGGåˆ†ç»„è®­ç»ƒå¼€å…³')
    parser.add_argument('--group', type=str, default='all', choices=['all', 'bg0', 'bg1', 'allgroup'],
                        help='é€‰æ‹©è®­ç»ƒæ•°æ®åˆ†ç»„: all(å…¨éƒ¨), bg0(ä¸è¡¥å…‰), bg1(è¡¥å…‰), allgroup(å…¨éƒ¨åˆ†ç»„)')
    parser.add_argument('--data_path', type=str, default=None,
                        help='æ•°æ®é›†è·¯å¾„ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=None,
                        help='æ‰¹æ¬¡å¤§å°ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´')
    parser.add_argument('--epochs', type=int, default=30,
                        help='è®­ç»ƒè½®æ•° (é»˜è®¤: 30)')
    parser.add_argument('--lr', type=float, default=0.001,
                        help='åŸºç¡€å­¦ä¹ ç‡ (é»˜è®¤: 0.001)')
    parser.add_argument('--debug', action='store_true',
                        help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„æ¨¡å‹ç»“æ„ä¿¡æ¯')
    args = parser.parse_args()
    print(f"å‘½ä»¤è¡Œå‚æ•°è§£æå®Œæˆ: group={args.group}, data_path={args.data_path}, batch_size={args.batch_size}, epochs={args.epochs}, lr={args.lr}, debug={args.debug}", flush=True)

    print("æ­£åœ¨æ£€æµ‹CUDAè®¾å¤‡...", flush=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}", flush=True)
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}", flush=True)
    if torch.cuda.is_available():
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}", flush=True)
        print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}", flush=True)
    
    # å…¨å±€é…ç½®å‚æ•°ï¼ˆé¿å…å˜é‡ä½œç”¨åŸŸé—®é¢˜ï¼‰
    batch_size = args.batch_size if args.batch_size else 192  # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–é»˜è®¤å€¼
    num_workers = 6   # ä¼˜åŒ–é…ç½®ï¼ˆå¿«ï¼‰
    use_amp = True    # æ··åˆç²¾åº¦è®­ç»ƒå¼€å…³
    base_lr = args.lr  # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    num_epochs = args.epochs  # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    
    # æ™ºèƒ½batch_sizeè°ƒæ•´ï¼ˆä»…åœ¨æœªæŒ‡å®šæ—¶ï¼‰
    if args.batch_size is None:
        if torch.cuda.is_available():
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"æ£€æµ‹åˆ°GPUæ˜¾å­˜: {gpu_memory_gb:.1f} GB", flush=True)
            
            if gpu_memory_gb >= 20:  # RTX 4090ç­‰é«˜ç«¯å¡
                batch_size = 192
                print("é«˜ç«¯GPUé…ç½®: batch_size=192", flush=True)
            elif gpu_memory_gb >= 10:  # RTX 3080ç­‰ä¸­ç«¯å¡
                batch_size = 96
                print("ä¸­ç«¯GPUé…ç½®: batch_size=96", flush=True)
            else:  # ä½ç«¯GPU
                batch_size = 32
                print("ä½ç«¯GPUé…ç½®: batch_size=32", flush=True)
        else:
            batch_size = 16
            print("CPUæ¨¡å¼: batch_size=16", flush=True)
    else:
        print(f"ä½¿ç”¨æŒ‡å®šçš„batch_size: {batch_size}", flush=True)
    
    # ä¼˜åŒ–DataLoaderé…ç½®
    pin_memory = True    # ä¼˜åŒ–é…ç½®ï¼ˆå¿«ï¼‰
    
    print(f"æœ€ç»ˆé…ç½®: batch_size={batch_size}, num_workers={num_workers}, use_amp={use_amp}, pin_memory={pin_memory}", flush=True)
    
    # GPUå†…å­˜ç›‘æ§
    if torch.cuda.is_available():
        print(f"GPUå†…å­˜çŠ¶æ€: {torch.cuda.get_device_name(0)}")
        print(f"æ€»æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"å½“å‰å·²ç”¨æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        print(f"å½“å‰ç¼“å­˜æ˜¾å­˜: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
    
    # æ•°æ®å¢å¼ºç­–ç•¥ï¼šè®­ç»ƒå’ŒéªŒè¯ä½¿ç”¨ä¸åŒçš„transform
    # ç§‘å­¦å®éªŒå›¾åƒæ•°æ®å¢å¼ºç­–ç•¥è°ƒæ•´ï¼š
    # - ç§»é™¤é¢œè‰²æ‰°åŠ¨ï¼šå…‰æ–‘é¢œè‰²ä¸æµ“åº¦ç›´æ¥ç›¸å…³ï¼Œä¸åº”æ”¹å˜
    # - ç§»é™¤æ—‹è½¬ï¼šæ¿€å…‰å…¥å°„è§’åº¦å›ºå®šï¼Œæ—‹è½¬ä¼šæ”¹å˜å…‰æ–‘çš„ç‰©ç†ç‰¹å¾
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        # ä»…ä¿ç•™åŸºç¡€é¢„å¤„ç†ï¼Œä¸è¿›è¡Œå¯èƒ½å½±å“ç‰©ç†ç‰¹å¾çš„å¢å¼º
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    print("æ•°æ®å¢å¼ºç­–ç•¥:", flush=True)
    print("  è®­ç»ƒé›†: ä»…åŸºç¡€é¢„å¤„ç†ï¼Œä¿æŒç‰©ç†ç‰¹å¾å®Œæ•´æ€§", flush=True)
    print("  éªŒè¯/æµ‹è¯•é›†: ä»…åŸºç¡€é¢„å¤„ç†ï¼Œæ— å¢å¼º", flush=True)
    print("  è¯´æ˜: ç§»é™¤é¢œè‰²æ‰°åŠ¨å’Œæ—‹è½¬ä»¥ä¿æŒå…‰æ–‘çš„ç‰©ç†ç‰¹å¾", flush=True)
    
    # æ™ºèƒ½æ•°æ®è·¯å¾„æ£€æµ‹
    if args.data_path:
        dataset_path = args.data_path
    else:
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®é›†é…ç½®
        config = DatasetConfig()
        dataset_path = config.get_best_dataset_path()
        
        if dataset_path is None:
            print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®é›†ï¼", flush=True)
            print("å¯èƒ½çš„è·¯å¾„:", flush=True)
            for path in config.CLEAN_DATASET_PATHS:
                print(f"  {path}", flush=True)
            return
        
        print(f"è‡ªåŠ¨æ£€æµ‹åˆ°æ•°æ®è·¯å¾„: {dataset_path}", flush=True)
    
    # æ·»åŠ è·¯å¾„æ£€æŸ¥å’Œè°ƒè¯•ä¿¡æ¯
    print(f"ä½¿ç”¨æ•°æ®è·¯å¾„: {dataset_path}")
    if not os.path.exists(dataset_path):
        print(f"é”™è¯¯ï¼šæ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„: {dataset_path}")
        return
    
    print(f"æ•°æ®è·¯å¾„å­˜åœ¨ï¼Œå¼€å§‹æ‰«æå›¾åƒæ–‡ä»¶...")
    
    # éªŒè¯æ•°æ®æ ¼å¼
    config = DatasetConfig()
    format_validation = config.validate_dataset_format(dataset_path)
    if "error" not in format_validation:
        print(f"ğŸ“Š æ•°æ®æ ¼å¼æ£€æŸ¥:")
        print(f"   æ€»æ–‡ä»¶æ•°: {format_validation['total_files']}")
        print(f"   degæ ¼å¼æ–‡ä»¶: {format_validation['deg_format_files']}")
        print(f"   æ—§æ ¼å¼æ–‡ä»¶: {format_validation['old_format_files']}")
        print(f"   degæ ¼å¼æ¯”ä¾‹: {format_validation['deg_format_rate']:.1%}")
        
        if format_validation['deg_format_rate'] < 0.9:
            print("âš ï¸ è­¦å‘Šï¼šæ•°æ®é›†ä¸­å­˜åœ¨è¾ƒå¤šédegæ ¼å¼æ–‡ä»¶ï¼Œå»ºè®®å…ˆè¿è¡Œæ ¼å¼ç»Ÿä¸€å·¥å…·")
            print("   python src/unified_format_converter.py --dataset clean")
    else:
        print(f"âš ï¸ æ•°æ®æ ¼å¼æ£€æŸ¥å¤±è´¥: {format_validation['error']}")

    if args.group in ['all', 'allgroup']:
        print("\nã€å…¨éƒ¨æ•°æ®è®­ç»ƒã€‘")
        print("æ­£åœ¨åˆå§‹åŒ–æ•°æ®é›†ï¼Œè¯·ç¨å€™...")
        
        # åˆ›å»ºå®Œæ•´æ•°æ®é›†ç”¨äºåˆ’åˆ†
        full_dataset = FastImageDataset(root_dir=dataset_path, transform=None)
        print(f"æ•°æ®é›†åˆå§‹åŒ–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(full_dataset)} å¼ å›¾åƒ")
        if len(full_dataset) == 0:
            print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶ï¼")
            return
            
        train_size = int(0.7 * len(full_dataset))
        val_size = int(0.15 * len(full_dataset))
        test_size = len(full_dataset) - train_size - val_size
        
        # æ­£ç¡®çš„æ•°æ®é›†åˆ’åˆ†æ–¹å¼
        generator = torch.Generator().manual_seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
        train_dataset_base, val_dataset_base, test_dataset_base = torch.utils.data.random_split(
            full_dataset, [train_size, val_size, test_size], generator=generator
        )
        
        # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ç±»æ¥åº”ç”¨ä¸åŒçš„transform
        class TransformDataset(torch.utils.data.Dataset):
            def __init__(self, base_dataset, transform, original_dataset):
                self.base_dataset = base_dataset
                self.transform = transform
                self.original_dataset = original_dataset
                
            def __len__(self):
                return len(self.base_dataset)
                
            def __getitem__(self, idx):
                # è·å–åŸå§‹ç´¢å¼•
                original_idx = self.base_dataset.indices[idx]
                # ä»åŸå§‹æ•°æ®é›†è·å–åŸå§‹å›¾åƒå’Œæ ‡ç­¾
                img_path = self.original_dataset.image_files[original_idx]
                concentration = self.original_dataset.concentrations[original_idx]
                
                # ç®€åŒ–çš„å›¾åƒåŠ è½½ï¼ˆæ•°æ®é›†å·²é¢„å…ˆéªŒè¯ï¼‰
                try:
                    img = Image.open(img_path).convert('RGB')
                except Exception as e:
                    # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œä½†ä¿ç•™ä½œä¸ºæœ€åé˜²çº¿
                    print(f"æ„å¤–é”™è¯¯ï¼šæ— æ³•è¯»å–å·²éªŒè¯çš„å›¾åƒ {img_path}: {e}")
                    img = Image.new('RGB', (224, 224), color='black')
                
                if self.transform:
                    img = self.transform(img)
                    
                return img, concentration
        
        # åˆ›å»ºå¸¦æœ‰ä¸åŒtransformçš„æ•°æ®é›†
        train_dataset = TransformDataset(train_dataset_base, train_transform, full_dataset)
        val_dataset = TransformDataset(val_dataset_base, val_test_transform, full_dataset)
        test_dataset = TransformDataset(test_dataset_base, val_test_transform, full_dataset)
        
        print(f"æ•°æ®é›†åˆ’åˆ†:")
        print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾åƒ (ä½¿ç”¨æ•°æ®å¢å¼º)")
        print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾åƒ (æ— å¢å¼º)")
        print(f"æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾åƒ (æ— å¢å¼º)")
        
        print(f"RTX 4090é«˜æ€§èƒ½é…ç½® - batch_size={batch_size}, num_workers={num_workers}", flush=True)
        print("å¤§å¹…å¢åŠ batch_sizeå……åˆ†åˆ©ç”¨GPUï¼Œç›®æ ‡æ˜¾å­˜ä½¿ç”¨18-22GB", flush=True)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)
        model = VGGRegressionCBAM(freeze_features=True, debug_mode=args.debug).to(device)
        criterion = nn.MSELoss()
        
        # æ ¹æ®batch_sizeè°ƒæ•´å­¦ä¹ ç‡ï¼ˆå¤§batchè®­ç»ƒæœ€ä½³å®è·µï¼‰
        lr = base_lr * (batch_size / 32)  # çº¿æ€§ç¼©æ”¾
        
        # ä¼˜åŒ–å™¨é…ç½®ï¼šè®­ç»ƒæ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬CBAMå±‚å’Œå›å½’å¤´ï¼‰
        trainable_params = [p for p in model.parameters() if p.requires_grad]
        optimizer = torch.optim.Adam(trainable_params, lr=lr, weight_decay=1e-4)
        
        # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
        
        print(f"å­¦ä¹ ç‡è°ƒæ•´: base_lr={base_lr}, batch_size={batch_size}, final_lr={lr:.6f}", flush=True)
        print(f"ä¼˜åŒ–å™¨é…ç½®: è®­ç»ƒ{len(trainable_params)}ä¸ªå¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬CBAMå±‚å’Œå›å½’å¤´ï¼‰", flush=True)
        
        start_epoch = 0
        best_model_path = 'best_vgg_model.pth'
        if os.path.exists(best_model_path):
            print('æ£€æµ‹åˆ°å·²æœ‰best_vgg_model.pthï¼Œæ­£åœ¨åŠ è½½æƒé‡å¹¶æ–­ç‚¹ç»­è®­...')
            try:
                model.load_state_dict(torch.load(best_model_path, map_location=device))
                print("æƒé‡åŠ è½½æˆåŠŸ", flush=True)
            except Exception as e:
                print(f"æƒé‡åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ", flush=True)
        
        # å¯ç”¨CUDNN benchmarkä»¥æå‡æ€§èƒ½
        enable_cudnn_benchmark()
        
        print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")
        print("æ­£åœ¨è¿›å…¥ç¬¬ä¸€ä¸ªepochï¼Œæ•°æ®åŠ è½½å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
        train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, start_epoch=start_epoch, use_amp=use_amp, scheduler=scheduler, model_save_path=best_model_path)
        
        # æµ‹è¯•é˜¶æ®µ
        model.load_state_dict(torch.load(best_model_path, map_location=device))
        model.eval()
        test_predictions = []
        test_targets = []
        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs = inputs.to(device)
                if use_amp:
                    with torch.amp.autocast('cuda'):
                        predictions = model(inputs)
                else:
                    predictions = model(inputs)
                test_predictions.extend(predictions.cpu().numpy())
                test_targets.extend(targets.numpy())
        test_predictions = np.array(test_predictions)
        test_targets = np.array(test_targets)
        mse = mean_squared_error(test_targets, test_predictions)
        r2 = r2_score(test_targets, test_predictions)
        print("\nå…¨éƒ¨æ•°æ®æµ‹è¯•é›†ç»“æœ:")
        print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.3f}")
        print(f"RÂ² åˆ†æ•°: {r2:.3f}")
        
        # è·å–æ ‡ç­¾
        labels = get_labels(CHINESE_SUPPORTED)
        
        plt.figure(figsize=(10, 6))
        plt.scatter(test_targets, test_predictions, alpha=0.5)
        plt.plot([min(test_targets), max(test_targets)], [min(test_targets), max(test_targets)], 'r--')
        plt.xlabel(labels['true_concentration'])
        plt.ylabel(labels['predicted_concentration'])
        plt.title(f"{labels['all_data']}{labels['test_results']} (RÂ² = {r2:.3f})")
        plt.savefig("images/vgg_final_prediction_plot_all.png")
        plt.close()

    if args.group in ['bg0', 'bg1', 'allgroup']:
        group_list = [args.group] if args.group in ['bg0', 'bg1'] else ['bg0', 'bg1']
        for bg_type in group_list:
            print(f"\nã€ä»…{bg_type}å›¾åƒè®­ç»ƒã€‘")
            
            # åˆ›å»ºæ•°æ®é›†ç”¨äºåˆ’åˆ†
            full_bg_dataset = FastImageDataset(root_dir=dataset_path, transform=None, bg_type=bg_type)
            if len(full_bg_dataset) < 10:
                print(f"{bg_type}æ ·æœ¬è¿‡å°‘({len(full_bg_dataset)}å¼ )ï¼Œè·³è¿‡...")
                continue
                
            train_size = int(0.7 * len(full_bg_dataset))
            val_size = int(0.15 * len(full_bg_dataset))
            test_size = len(full_bg_dataset) - train_size - val_size
            
            # ç¡®ä¿æ¯ä¸ªé›†åˆè‡³å°‘æœ‰1ä¸ªæ ·æœ¬
            if val_size == 0:
                val_size = 1
                train_size -= 1
            if test_size == 0:
                test_size = 1
                train_size -= 1
                
            # æ­£ç¡®çš„æ•°æ®é›†åˆ’åˆ†æ–¹å¼
            generator = torch.Generator().manual_seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
            train_dataset_base, val_dataset_base, test_dataset_base = torch.utils.data.random_split(
                full_bg_dataset, [train_size, val_size, test_size], generator=generator
            )
            
            # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ç±»æ¥åº”ç”¨ä¸åŒçš„transform
            class TransformDatasetBG(torch.utils.data.Dataset):
                def __init__(self, base_dataset, transform, original_dataset):
                    self.base_dataset = base_dataset
                    self.transform = transform
                    self.original_dataset = original_dataset
                    
                def __len__(self):
                    return len(self.base_dataset)
                    
                def __getitem__(self, idx):
                    # è·å–åŸå§‹ç´¢å¼•
                    original_idx = self.base_dataset.indices[idx]
                    # ä»åŸå§‹æ•°æ®é›†è·å–åŸå§‹å›¾åƒå’Œæ ‡ç­¾
                    img_path = self.original_dataset.image_files[original_idx]
                    concentration = self.original_dataset.concentrations[original_idx]
                    
                    # ç®€åŒ–çš„å›¾åƒåŠ è½½ï¼ˆæ•°æ®é›†å·²é¢„å…ˆéªŒè¯ï¼‰
                    try:
                        img = Image.open(img_path).convert('RGB')
                    except Exception as e:
                        # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œä½†ä¿ç•™ä½œä¸ºæœ€åé˜²çº¿
                        print(f"æ„å¤–é”™è¯¯ï¼šæ— æ³•è¯»å–å·²éªŒè¯çš„å›¾åƒ {img_path}: {e}")
                        img = Image.new('RGB', (224, 224), color='black')
                    
                    if self.transform:
                        img = self.transform(img)
                        
                    return img, concentration
            
            # åˆ›å»ºå¸¦æœ‰ä¸åŒtransformçš„æ•°æ®é›†
            train_dataset = TransformDatasetBG(train_dataset_base, train_transform, full_bg_dataset)
            val_dataset = TransformDatasetBG(val_dataset_base, val_test_transform, full_bg_dataset)
            test_dataset = TransformDatasetBG(test_dataset_base, val_test_transform, full_bg_dataset)
            
            print(f"{bg_type}æ•°æ®é›†åˆ’åˆ†:")
            print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾åƒ (ä½¿ç”¨æ•°æ®å¢å¼º)")
            print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾åƒ (æ— å¢å¼º)")
            print(f"æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾åƒ (æ— å¢å¼º)")
            
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)
            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)
            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)
            model = VGGRegressionCBAM(freeze_features=True, debug_mode=args.debug).to(device)
            criterion = nn.MSELoss()
            
            # æ ¹æ®batch_sizeè°ƒæ•´å­¦ä¹ ç‡ï¼ˆå¤§batchè®­ç»ƒæœ€ä½³å®è·µï¼‰
            lr = base_lr * (batch_size / 32)  # çº¿æ€§ç¼©æ”¾
            
            # ä¼˜åŒ–å™¨é…ç½®ï¼šè®­ç»ƒæ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬CBAMå±‚å’Œå›å½’å¤´ï¼‰
            trainable_params = [p for p in model.parameters() if p.requires_grad]
            optimizer = torch.optim.Adam(trainable_params, lr=lr, weight_decay=1e-4)
            
            # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
            
            print(f"å­¦ä¹ ç‡è°ƒæ•´: base_lr={base_lr}, batch_size={batch_size}, final_lr={lr:.6f}", flush=True)
            print(f"ä¼˜åŒ–å™¨é…ç½®: è®­ç»ƒ{len(trainable_params)}ä¸ªå¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬CBAMå±‚å’Œå›å½’å¤´ï¼‰", flush=True)
            
            best_model_path = f'best_vgg_model_{bg_type}.pth'
            start_epoch = 0
            
            # æ–­ç‚¹ç»­è®­é€»è¾‘
            if os.path.exists(best_model_path):
                print(f'æ£€æµ‹åˆ°å·²æœ‰{best_model_path}ï¼Œæ­£åœ¨åŠ è½½æƒé‡å¹¶æ–­ç‚¹ç»­è®­...')
                try:
                    model.load_state_dict(torch.load(best_model_path, map_location=device))
                    print("æƒé‡åŠ è½½æˆåŠŸ", flush=True)
                except Exception as e:
                    print(f"æƒé‡åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ", flush=True)
            
            # å¯ç”¨CUDNN benchmarkä»¥æå‡æ€§èƒ½
            enable_cudnn_benchmark()
            
            print(f"\nå¼€å§‹è®­ç»ƒ{bg_type}æ¨¡å‹...")
            train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, start_epoch=start_epoch, use_amp=use_amp, scheduler=scheduler, model_save_path=best_model_path)
            
            # æµ‹è¯•é˜¶æ®µ
            model.load_state_dict(torch.load(best_model_path, map_location=device))
            model.eval()
            test_predictions = []
            test_targets = []
            with torch.no_grad():
                for inputs, targets in test_loader:
                    inputs = inputs.to(device)
                    if use_amp:
                        with torch.amp.autocast('cuda'):
                            predictions = model(inputs)
                    else:
                        predictions = model(inputs)
                    test_predictions.extend(predictions.cpu().numpy())
                    test_targets.extend(targets.numpy())
            test_predictions = np.array(test_predictions)
            test_targets = np.array(test_targets)
            mse = mean_squared_error(test_targets, test_predictions)
            r2 = r2_score(test_targets, test_predictions)
            print(f"\n{bg_type}æµ‹è¯•é›†ç»“æœ:")
            print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.3f}")
            print(f"RÂ² åˆ†æ•°: {r2:.3f}")
            
            # è·å–æ ‡ç­¾
            labels = get_labels(CHINESE_SUPPORTED)
            
            plt.figure(figsize=(10, 6))
            plt.scatter(test_targets, test_predictions, alpha=0.5)
            plt.plot([min(test_targets), max(test_targets)], [min(test_targets), max(test_targets)], 'r--')
            plt.xlabel(labels['true_concentration'])
            plt.ylabel(labels['predicted_concentration'])
            plt.title(f'{bg_type}{labels["test_results"]} (RÂ² = {r2:.3f})')
            plt.savefig(f'vgg_final_prediction_plot_{bg_type}.png')
            plt.close()

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­", flush=True)
    except Exception as e:
        print(f"\nç¨‹åºè¿è¡Œå‡ºé”™: {e}", flush=True)
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ç¨‹åºç»“æŸï¼Œå·²æ¸…ç†GPUç¼“å­˜", flush=True) 